{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6UBNpL/Q8YSna8tQn2mDu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sidharth-Darwin/PyTorch_Programs/blob/main/denoising_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bO2X3iLri7nA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import MNIST\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djODJZf-1RzM",
        "outputId": "41d685a9-5e96-4975-d1d3-7558a930c4e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a8488a48c70>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUaQWMwioh5K",
        "outputId": "a53a538c-37b4-4494-bc83-3401c480c27c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NoisyMNIST(Dataset):\n",
        "    def __init__(self, img_data_path, train=True, noise_factor=0.2):\n",
        "        super(NoisyMNIST, self).__init__()\n",
        "        self.img_data_path = img_data_path\n",
        "        self.img_transforms = ToTensor()\n",
        "        self.noise_factor = noise_factor\n",
        "        self.train = train\n",
        "        if self.train:\n",
        "            self.mnist_df = MNIST(self.img_data_path, transform=self.img_transforms, train=True, download=True)\n",
        "        else:\n",
        "            self.mnist_df = MNIST(self.img_data_path, transform=self.img_transforms, train=False, download=True)\n",
        "        self.len = len(self.mnist_df)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        clean_img, _ = self.mnist_df[index]\n",
        "        noisy_img = clean_img + self.noise_factor * torch.randn_like(clean_img)\n",
        "        noisy_img = torch.clip(noisy_img, 0.0, 1.0)\n",
        "\n",
        "        return (noisy_img, clean_img)"
      ],
      "metadata": {
        "id": "P8GeYZXvjcRe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = NoisyMNIST(\"/content/data\")\n",
        "test_ds = NoisyMNIST(\"/content/data\", train=False)"
      ],
      "metadata": {
        "id": "wpYbA6kQjy0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e84a23-cf3c-4b3b-f76f-93ec83e59ec7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /content/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 58920906.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/MNIST/raw/train-images-idx3-ubyte.gz to /content/data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /content/data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1901718.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/MNIST/raw/train-labels-idx1-ubyte.gz to /content/data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /content/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 14559679.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4641941.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds), len(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFZx15GrkAyP",
        "outputId": "a8385e8f-5973-458a-d4b4-e66ebbd608db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_noisy_clean_output(noisy, clean, output=None):\n",
        "    noisy = noisy.detach().cpu().squeeze()\n",
        "    clean = clean.detach().cpu().squeeze()\n",
        "    if output is None:\n",
        "        fig, axs = plt.subplots(1, 2)\n",
        "        fig.suptitle(\"Noisy vs Clean\")\n",
        "        axs[0].imshow(noisy, cmap=\"binary\")\n",
        "        axs[0].set_title(\"Noisy\")\n",
        "        axs[0].axis(\"off\")\n",
        "        axs[1].imshow(clean, cmap=\"binary\")\n",
        "        axs[1].set_title(\"Clean\")\n",
        "        axs[1].axis(\"off\")\n",
        "    else:\n",
        "        output = output.detach().cpu().squeeze()\n",
        "        fig, axs = plt.subplots(1, 3)\n",
        "        fig.suptitle(\"Noisy vs Clean vs Output\")\n",
        "        axs[0].imshow(noisy, cmap=\"binary\")\n",
        "        axs[0].set_title(\"Noisy\")\n",
        "        axs[0].axis(\"off\")\n",
        "        axs[1].imshow(clean, cmap=\"binary\")\n",
        "        axs[1].set_title(\"Clean\")\n",
        "        axs[1].axis(\"off\")\n",
        "        axs[2].imshow(output, cmap=\"binary\")\n",
        "        axs[2].set_title(\"Output\")\n",
        "        axs[2].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3YULLo2oww6y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noisy, clean = train_ds[5]\n",
        "compare_noisy_clean_output(noisy, clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "_Vwl7LU_kiba",
        "outputId": "87c8c1a0-e847-40f7-d169-897061c8c25e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noisy.shape, clean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-67I4j6lcP_",
        "outputId": "4fa80d31-4360-4f30-a258-23ddcedc8249"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), torch.Size([1, 28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_dl = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "SthRV-M9kCtI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dl), len(test_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMq719HVkV0w",
        "outputId": "08750c93-78bd-4940-c6f8-1ad7920c458b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1875, 313)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(32, 16, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        return self.encoder(inp)\n",
        "\n",
        "encoder = Encoder()\n",
        "x = torch.rand(1, 1, 28, 28)\n",
        "print(\"Encoder input shape:\", x.shape)\n",
        "total_n_params = 0\n",
        "for layer in encoder.encoder:\n",
        "    x = layer(x)\n",
        "    n_params_per_layer = sum([n.numel() for n in layer.parameters()])\n",
        "    total_n_params += n_params_per_layer\n",
        "    print(f\"{layer._get_name():<15}: {str(x.shape):<30}: {n_params_per_layer:<10}\")\n",
        "print(f\"Total number of parameters: {total_n_params}\")\n",
        "print(\"Encoder output shape:\", encoder(torch.rand(1, 1, 28, 28)).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61Fm0oyTkgU4",
        "outputId": "59aa1caf-906f-4838-b3bf-a317a2b4f8a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder input shape: torch.Size([1, 1, 28, 28])\n",
            "Conv2d         : torch.Size([1, 64, 28, 28])   : 640       \n",
            "BatchNorm2d    : torch.Size([1, 64, 28, 28])   : 128       \n",
            "ReLU           : torch.Size([1, 64, 28, 28])   : 0         \n",
            "MaxPool2d      : torch.Size([1, 64, 14, 14])   : 0         \n",
            "Conv2d         : torch.Size([1, 32, 14, 14])   : 18464     \n",
            "BatchNorm2d    : torch.Size([1, 32, 14, 14])   : 64        \n",
            "ReLU           : torch.Size([1, 32, 14, 14])   : 0         \n",
            "MaxPool2d      : torch.Size([1, 32, 7, 7])     : 0         \n",
            "Conv2d         : torch.Size([1, 16, 7, 7])     : 4624      \n",
            "BatchNorm2d    : torch.Size([1, 16, 7, 7])     : 32        \n",
            "ReLU           : torch.Size([1, 16, 7, 7])     : 0         \n",
            "Total number of parameters: 23952\n",
            "Encoder output shape: torch.Size([1, 16, 7, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(32, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(64, 1, 3, stride=1, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, inp):\n",
        "        return self.decoder(inp)\n",
        "\n",
        "decoder = Decoder()\n",
        "total_n_params = 0\n",
        "print(\"Decoder input shape:\", x.shape)\n",
        "for layer in decoder.decoder:\n",
        "    x = layer(x)\n",
        "    n_params_per_layer= sum([n.numel() for n in layer.parameters()])\n",
        "    total_n_params += n_params_per_layer\n",
        "    print(f\"{layer._get_name():<15}: {x.shape} : {n_params_per_layer:<10}\")\n",
        "print(f\"Total number of parameters: {total_n_params}\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smJ2Jww6mUTH",
        "outputId": "ede73971-95d4-4458-f525-6869d321c649"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder input shape: torch.Size([1, 16, 7, 7])\n",
            "Conv2d         : torch.Size([1, 32, 7, 7]) : 4640      \n",
            "BatchNorm2d    : torch.Size([1, 32, 7, 7]) : 64        \n",
            "ReLU           : torch.Size([1, 32, 7, 7]) : 0         \n",
            "Upsample       : torch.Size([1, 32, 14, 14]) : 0         \n",
            "Conv2d         : torch.Size([1, 64, 14, 14]) : 18496     \n",
            "BatchNorm2d    : torch.Size([1, 64, 14, 14]) : 128       \n",
            "ReLU           : torch.Size([1, 64, 14, 14]) : 0         \n",
            "Upsample       : torch.Size([1, 64, 28, 28]) : 0         \n",
            "Conv2d         : torch.Size([1, 1, 28, 28]) : 577       \n",
            "Sigmoid        : torch.Size([1, 1, 28, 28]) : 0         \n",
            "Total number of parameters: 23905\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, inp):\n",
        "        x = self.encoder(inp)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "model = AutoEncoder()\n",
        "print(\"Autoencoder Output shape:\", model(torch.rand(1, 1, 28, 28)).shape)\n",
        "print(sum([x.numel() for x in model.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JIkiDfCm76C",
        "outputId": "465be2c5-b158-4f7f-a5d8-88ed76edb50d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autoencoder Output shape: torch.Size([1, 1, 28, 28])\n",
            "47857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopperMinDelta:\n",
        "    def __init__(self, patience=1, min_delta=0, after_epoch=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.after_epoch = after_epoch\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = float('inf')\n",
        "        self.saved_state_dict = None\n",
        "\n",
        "    def early_stop(self, validation_loss, state_dict, epoch=float('inf')):\n",
        "        if epoch > self.after_epoch and validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "            self.saved_state_dict = state_dict\n",
        "        elif epoch > self.after_epoch and validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "early_stopper = EarlyStopperMinDelta(patience=5, min_delta=0.0001, after_epoch=10)"
      ],
      "metadata": {
        "id": "JuDdzU7MooQc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoEncoder().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "zJUJmiRhn921"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 500\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"EPOCH {epoch+1}\")\n",
        "\n",
        "    print(\"Training...\")\n",
        "    avg_train_loss = 0.0\n",
        "    model.train()\n",
        "    for noisy, clean in train_dl:\n",
        "        noisy = noisy.to(device)\n",
        "        clean = clean.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(noisy)\n",
        "        loss = criterion(out, clean)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        avg_train_loss += loss.item()\n",
        "    avg_train_loss /= len(train_dl)\n",
        "    print(\"Avg train loss:\", avg_train_loss)\n",
        "\n",
        "    print(\"Validating...\")\n",
        "    avg_val_loss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for noisy, clean in test_dl:\n",
        "            noisy = noisy.to(device)\n",
        "            clean = clean.to(device)\n",
        "            out = model(noisy)\n",
        "            loss = criterion(out, clean)\n",
        "            avg_val_loss += loss.item()\n",
        "    avg_val_loss /= len(test_dl)\n",
        "    print(\"Avg val loss:\", avg_val_loss)\n",
        "\n",
        "    if early_stopper.early_stop(avg_val_loss, model.state_dict(), epoch):\n",
        "        print(f\"Early stopped at epoch {epoch+1}\")\n",
        "        model.load_state_dict(early_stopper.saved_state_dict)\n",
        "        break\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j226rAvSoKLE",
        "outputId": "2a1e3254-15ff-49f3-ef8f-e93e2a1ed49a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1\n",
            "Training...\n",
            "Avg train loss: 0.014396872648348411\n",
            "Validating...\n",
            "Avg val loss: 0.005732215017068405\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 2\n",
            "Training...\n",
            "Avg train loss: 0.005328846991683046\n",
            "Validating...\n",
            "Avg val loss: 0.00457722044805773\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 3\n",
            "Training...\n",
            "Avg train loss: 0.004587098725140095\n",
            "Validating...\n",
            "Avg val loss: 0.004338772861084666\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 4\n",
            "Training...\n",
            "Avg train loss: 0.004239713711291552\n",
            "Validating...\n",
            "Avg val loss: 0.0038917934865699694\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 5\n",
            "Training...\n",
            "Avg train loss: 0.003990278578425447\n",
            "Validating...\n",
            "Avg val loss: 0.003709692749739312\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 6\n",
            "Training...\n",
            "Avg train loss: 0.0038268198408186434\n",
            "Validating...\n",
            "Avg val loss: 0.004233954875274731\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 7\n",
            "Training...\n",
            "Avg train loss: 0.003707208967333039\n",
            "Validating...\n",
            "Avg val loss: 0.0034911334789849034\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 8\n",
            "Training...\n",
            "Avg train loss: 0.003600497523943583\n",
            "Validating...\n",
            "Avg val loss: 0.0034300278955564714\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 9\n",
            "Training...\n",
            "Avg train loss: 0.003536503130321701\n",
            "Validating...\n",
            "Avg val loss: 0.003342879967341503\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 10\n",
            "Training...\n",
            "Avg train loss: 0.0034587562039494514\n",
            "Validating...\n",
            "Avg val loss: 0.0033236979023395733\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 11\n",
            "Training...\n",
            "Avg train loss: 0.003398402586579323\n",
            "Validating...\n",
            "Avg val loss: 0.0032628328686716934\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 12\n",
            "Training...\n",
            "Avg train loss: 0.0033522747110575437\n",
            "Validating...\n",
            "Avg val loss: 0.0032655291918355723\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 13\n",
            "Training...\n",
            "Avg train loss: 0.0033106667689979078\n",
            "Validating...\n",
            "Avg val loss: 0.0032084922212512255\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 14\n",
            "Training...\n",
            "Avg train loss: 0.0032757182590663434\n",
            "Validating...\n",
            "Avg val loss: 0.0031803839642126053\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 15\n",
            "Training...\n",
            "Avg train loss: 0.0032413884016374746\n",
            "Validating...\n",
            "Avg val loss: 0.0031280464971789154\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 16\n",
            "Training...\n",
            "Avg train loss: 0.0032165442275504273\n",
            "Validating...\n",
            "Avg val loss: 0.003102650586218118\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 17\n",
            "Training...\n",
            "Avg train loss: 0.0031821536898612975\n",
            "Validating...\n",
            "Avg val loss: 0.0030928949324098734\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 18\n",
            "Training...\n",
            "Avg train loss: 0.003163560067365567\n",
            "Validating...\n",
            "Avg val loss: 0.0030737064723758557\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 19\n",
            "Training...\n",
            "Avg train loss: 0.0031380818015585344\n",
            "Validating...\n",
            "Avg val loss: 0.003154222599078958\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 20\n",
            "Training...\n",
            "Avg train loss: 0.003112001140912374\n",
            "Validating...\n",
            "Avg val loss: 0.0030406280963744124\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 21\n",
            "Training...\n",
            "Avg train loss: 0.0030994921879221996\n",
            "Validating...\n",
            "Avg val loss: 0.003037946013817058\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 22\n",
            "Training...\n",
            "Avg train loss: 0.003078637198234598\n",
            "Validating...\n",
            "Avg val loss: 0.003029224990953367\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 23\n",
            "Training...\n",
            "Avg train loss: 0.0030633940978596606\n",
            "Validating...\n",
            "Avg val loss: 0.0029938265356940393\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 24\n",
            "Training...\n",
            "Avg train loss: 0.003049441698441903\n",
            "Validating...\n",
            "Avg val loss: 0.0029961598862986117\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 25\n",
            "Training...\n",
            "Avg train loss: 0.0030304223106553158\n",
            "Validating...\n",
            "Avg val loss: 0.00297304989543919\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 26\n",
            "Training...\n",
            "Avg train loss: 0.0030207242373377083\n",
            "Validating...\n",
            "Avg val loss: 0.0029504863037980687\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 27\n",
            "Training...\n",
            "Avg train loss: 0.0030088880315423013\n",
            "Validating...\n",
            "Avg val loss: 0.0029441828217607337\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 28\n",
            "Training...\n",
            "Avg train loss: 0.0029954705274353424\n",
            "Validating...\n",
            "Avg val loss: 0.002937091383547448\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 29\n",
            "Training...\n",
            "Avg train loss: 0.002985202353571852\n",
            "Validating...\n",
            "Avg val loss: 0.002931050054681377\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 30\n",
            "Training...\n",
            "Avg train loss: 0.0029775632961342733\n",
            "Validating...\n",
            "Avg val loss: 0.0029059934880608282\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 31\n",
            "Training...\n",
            "Avg train loss: 0.0029686929501593112\n",
            "Validating...\n",
            "Avg val loss: 0.002904902335803825\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 32\n",
            "Training...\n",
            "Avg train loss: 0.002958230483531952\n",
            "Validating...\n",
            "Avg val loss: 0.0030052834034216005\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 33\n",
            "Training...\n",
            "Avg train loss: 0.002947281253958742\n",
            "Validating...\n",
            "Avg val loss: 0.0029458348942807498\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 34\n",
            "Training...\n",
            "Avg train loss: 0.0029380357706298432\n",
            "Validating...\n",
            "Avg val loss: 0.0028918401059953454\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 35\n",
            "Training...\n",
            "Avg train loss: 0.0029318152748048307\n",
            "Validating...\n",
            "Avg val loss: 0.00297326589607226\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 36\n",
            "Training...\n",
            "Avg train loss: 0.0029205996225277584\n",
            "Validating...\n",
            "Avg val loss: 0.0028843229856734837\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 37\n",
            "Training...\n",
            "Avg train loss: 0.0029223055277019737\n",
            "Validating...\n",
            "Avg val loss: 0.0028806439468476433\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 38\n",
            "Training...\n",
            "Avg train loss: 0.002914237581565976\n",
            "Validating...\n",
            "Avg val loss: 0.002866106688047941\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 39\n",
            "Training...\n",
            "Avg train loss: 0.0029064441416412593\n",
            "Validating...\n",
            "Avg val loss: 0.002874221494302344\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 40\n",
            "Training...\n",
            "Avg train loss: 0.0028993465688079596\n",
            "Validating...\n",
            "Avg val loss: 0.0028428005243535527\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 41\n",
            "Training...\n",
            "Avg train loss: 0.0028951341436554987\n",
            "Validating...\n",
            "Avg val loss: 0.0028468570366989784\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 42\n",
            "Training...\n",
            "Avg train loss: 0.002887528572852413\n",
            "Validating...\n",
            "Avg val loss: 0.0028534174559060664\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 43\n",
            "Training...\n",
            "Avg train loss: 0.0028808593639483055\n",
            "Validating...\n",
            "Avg val loss: 0.002839041947455595\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 44\n",
            "Training...\n",
            "Avg train loss: 0.0028787993108232816\n",
            "Validating...\n",
            "Avg val loss: 0.002835054690696704\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 45\n",
            "Training...\n",
            "Avg train loss: 0.002868753544986248\n",
            "Validating...\n",
            "Avg val loss: 0.002814293442555843\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 46\n",
            "Training...\n",
            "Avg train loss: 0.0028668072662005823\n",
            "Validating...\n",
            "Avg val loss: 0.002821339231829483\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 47\n",
            "Training...\n",
            "Avg train loss: 0.0028656998954713344\n",
            "Validating...\n",
            "Avg val loss: 0.002819307198295721\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 48\n",
            "Training...\n",
            "Avg train loss: 0.0028584355211506286\n",
            "Validating...\n",
            "Avg val loss: 0.00280922209135831\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 49\n",
            "Training...\n",
            "Avg train loss: 0.002850845253591736\n",
            "Validating...\n",
            "Avg val loss: 0.002817438776268603\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 50\n",
            "Training...\n",
            "Avg train loss: 0.002843917594725887\n",
            "Validating...\n",
            "Avg val loss: 0.002807390949757288\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 51\n",
            "Training...\n",
            "Avg train loss: 0.002841982870797316\n",
            "Validating...\n",
            "Avg val loss: 0.0027921692469713693\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 52\n",
            "Training...\n",
            "Avg train loss: 0.002842014681423704\n",
            "Validating...\n",
            "Avg val loss: 0.002819160179505809\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 53\n",
            "Training...\n",
            "Avg train loss: 0.002834935370956858\n",
            "Validating...\n",
            "Avg val loss: 0.0028192592746081255\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 54\n",
            "Training...\n",
            "Avg train loss: 0.00283405290817221\n",
            "Validating...\n",
            "Avg val loss: 0.0028145017382055046\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 55\n",
            "Training...\n",
            "Avg train loss: 0.0028249199935545524\n",
            "Validating...\n",
            "Avg val loss: 0.0027952662649781655\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 56\n",
            "Training...\n",
            "Avg train loss: 0.0028228689124186832\n",
            "Validating...\n",
            "Avg val loss: 0.0028057901557689657\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 57\n",
            "Training...\n",
            "Avg train loss: 0.0028231222803394\n",
            "Validating...\n",
            "Avg val loss: 0.0027768625357090094\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 58\n",
            "Training...\n",
            "Avg train loss: 0.0028202012725174427\n",
            "Validating...\n",
            "Avg val loss: 0.0027822607908005153\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 59\n",
            "Training...\n",
            "Avg train loss: 0.002815089069182674\n",
            "Validating...\n",
            "Avg val loss: 0.0027633637142257567\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 60\n",
            "Training...\n",
            "Avg train loss: 0.002811065762490034\n",
            "Validating...\n",
            "Avg val loss: 0.0027672719008054215\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 61\n",
            "Training...\n",
            "Avg train loss: 0.002807884157076478\n",
            "Validating...\n",
            "Avg val loss: 0.002799921653444727\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 62\n",
            "Training...\n",
            "Avg train loss: 0.0028066465873271226\n",
            "Validating...\n",
            "Avg val loss: 0.0027788128732099604\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 63\n",
            "Training...\n",
            "Avg train loss: 0.0028031971633434294\n",
            "Validating...\n",
            "Avg val loss: 0.002801917448711281\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 64\n",
            "Training...\n",
            "Avg train loss: 0.0027969111930578948\n",
            "Validating...\n",
            "Avg val loss: 0.0027565467677201135\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 65\n",
            "Training...\n",
            "Avg train loss: 0.0027996586746225753\n",
            "Validating...\n",
            "Avg val loss: 0.002780921923103757\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 66\n",
            "Training...\n",
            "Avg train loss: 0.002792194173236688\n",
            "Validating...\n",
            "Avg val loss: 0.002748122109254947\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 67\n",
            "Training...\n",
            "Avg train loss: 0.0027885559274504583\n",
            "Validating...\n",
            "Avg val loss: 0.002771488544099723\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 68\n",
            "Training...\n",
            "Avg train loss: 0.0027880504962056875\n",
            "Validating...\n",
            "Avg val loss: 0.002742554823579356\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 69\n",
            "Training...\n",
            "Avg train loss: 0.002783502121393879\n",
            "Validating...\n",
            "Avg val loss: 0.0027420678489898055\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 70\n",
            "Training...\n",
            "Avg train loss: 0.002787914108236631\n",
            "Validating...\n",
            "Avg val loss: 0.0027508565102712795\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 71\n",
            "Training...\n",
            "Avg train loss: 0.0027845220728466907\n",
            "Validating...\n",
            "Avg val loss: 0.002738834334948002\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 72\n",
            "Training...\n",
            "Avg train loss: 0.002775356109191974\n",
            "Validating...\n",
            "Avg val loss: 0.0027450121263750253\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 73\n",
            "Training...\n",
            "Avg train loss: 0.002773437426611781\n",
            "Validating...\n",
            "Avg val loss: 0.0027311582857677446\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 74\n",
            "Training...\n",
            "Avg train loss: 0.002771496548379461\n",
            "Validating...\n",
            "Avg val loss: 0.002754019291404956\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 75\n",
            "Training...\n",
            "Avg train loss: 0.002774981027469039\n",
            "Validating...\n",
            "Avg val loss: 0.0027529165184440704\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 76\n",
            "Training...\n",
            "Avg train loss: 0.002773418073107799\n",
            "Validating...\n",
            "Avg val loss: 0.0027409806868400628\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 77\n",
            "Training...\n",
            "Avg train loss: 0.0027651573774715266\n",
            "Validating...\n",
            "Avg val loss: 0.002728780112660731\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 78\n",
            "Training...\n",
            "Avg train loss: 0.0027617350742220876\n",
            "Validating...\n",
            "Avg val loss: 0.0027400525770307823\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 79\n",
            "Training...\n",
            "Avg train loss: 0.0027615100551396606\n",
            "Validating...\n",
            "Avg val loss: 0.0027565354906831877\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 80\n",
            "Training...\n",
            "Avg train loss: 0.0027606332277258236\n",
            "Validating...\n",
            "Avg val loss: 0.002724765732991524\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 81\n",
            "Training...\n",
            "Avg train loss: 0.0027570665057748554\n",
            "Validating...\n",
            "Avg val loss: 0.0027258561168330164\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 82\n",
            "Training...\n",
            "Avg train loss: 0.002753906500339508\n",
            "Validating...\n",
            "Avg val loss: 0.002727831140333138\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 83\n",
            "Training...\n",
            "Avg train loss: 0.002749230406805873\n",
            "Validating...\n",
            "Avg val loss: 0.0027319751568317127\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 84\n",
            "Training...\n",
            "Avg train loss: 0.0027568739405522745\n",
            "Validating...\n",
            "Avg val loss: 0.0027284103113943683\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 85\n",
            "Training...\n",
            "Avg train loss: 0.0027501818948735793\n",
            "Validating...\n",
            "Avg val loss: 0.0027478319137526777\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 86\n",
            "Training...\n",
            "Avg train loss: 0.002746141944701473\n",
            "Validating...\n",
            "Avg val loss: 0.0027189045064389323\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 87\n",
            "Training...\n",
            "Avg train loss: 0.0027486173403759796\n",
            "Validating...\n",
            "Avg val loss: 0.0027331069912225866\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 88\n",
            "Training...\n",
            "Avg train loss: 0.002742271428058545\n",
            "Validating...\n",
            "Avg val loss: 0.00274590016030275\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 89\n",
            "Training...\n",
            "Avg train loss: 0.002744224715853731\n",
            "Validating...\n",
            "Avg val loss: 0.0027065301171173683\n",
            "--------------------------------------------------------------------------------\n",
            "EPOCH 90\n",
            "Training...\n",
            "Avg train loss: 0.0027427484838912883\n",
            "Validating...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e69488ce7275>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mnoisy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-ac31682acfe9>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mclean_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnoisy_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_img\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mnoisy_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnoisy_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model_sd.pth\")"
      ],
      "metadata": {
        "id": "D40zqvgSpHtg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "noisy, clean = train_ds[5]\n",
        "output = model(noisy.unsqueeze(0).to(device))\n",
        "compare_noisy_clean_output(noisy, clean, output)"
      ],
      "metadata": {
        "id": "ZwL4gmvfpHv5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "52c6491d-de1f-4d43-ae16-f7b83359c260"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eVhWswHnpHyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzLMcPL6pH0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o_FAhMpvpH12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vQ5BoYmgpH6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}